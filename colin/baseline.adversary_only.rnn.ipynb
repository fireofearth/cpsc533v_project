{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a622b81",
   "metadata": {},
   "source": [
    "Simple Tag\n",
    "https://www.pettingzoo.ml/mpe/simple_tag\n",
    "\n",
    "> This is a predator-prey environment. Good agents (green) are faster and receive a negative reward for being hit by adversaries (red) (-10 for each collision). Adversaries are slower and are rewarded for hitting good agents (+10 for each collision). Obstacles (large black circles) block the way. By default, there is 1 good agent, 3 adversaries and 2 obstacles.\n",
    "\n",
    "Baseline agent algorithm with experience replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f7b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import enum\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import statistics\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "class TimeDelta(object):\n",
    "    def __init__(self, delta_time):\n",
    "        \"\"\"Convert time difference in seconds to days, hours, minutes, seconds.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        delta_time : float\n",
    "            Time difference in seconds.\n",
    "        \"\"\"\n",
    "        self.fractional, seconds = math.modf(delta_time)\n",
    "        seconds = int(seconds)\n",
    "        minutes, self.seconds = divmod(seconds, 60)\n",
    "        hours, self.minutes = divmod(minutes, 60)\n",
    "        self.days, self.hours = divmod(hours, 24)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.days}-{self.hours:02}:{self.minutes:02}:{self.seconds + self.fractional:02}\"\n",
    "\n",
    "from pettingzoo.mpe import simple_tag_v2\n",
    "from pettingzoo.utils import random_demo\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7724bfe",
   "metadata": {},
   "source": [
    "Arguments in instantiate environment.\n",
    "\n",
    "- num_good: number of good agents\n",
    "- num_adversaries: number of adversaries\n",
    "- num_obstacles: number of obstacles\n",
    "- max_cycles: number of frames (a step for each agent) until game terminates\n",
    "- continuous_actions: Whether agent action spaces are discrete(default) or continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08cbbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9858b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simple_tag_v2.env(\n",
    "    num_good=1,\n",
    "    num_adversaries=1,\n",
    "    num_obstacles=0,\n",
    "    max_cycles=30,\n",
    "    continuous_actions=False\n",
    ").unwrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cabc86",
   "metadata": {},
   "source": [
    "### What are the environment parameters?\n",
    "\n",
    "Adversaries (red) capture non-adversary (green). The map is a 2D grid and everything is initialized in the region [-1, +1]. There doesn't seem to be position clipping for out of bounds, but non-adversary agent are penalized for out of bounds.\n",
    "Agent's observation is a ndarray vector of concatenated data in the following order:\n",
    "\n",
    "1. current velocity (2,)\n",
    "2. current position (2,)\n",
    "3. relative position (2,) of each landmark\n",
    "4. relative position (2,) of each other agent\n",
    "5. velocity (2,) of each other non-adversary agent\n",
    "\n",
    "When there are 3 adverseries and 3 non-adversaries, then advarsary observation space is 24 dimensional and non-advarsary observation space is 22 dimensional.\n",
    "\n",
    "The environment is sequential. Agents move one at a time. Agents are either `adversary_*` for adversary or `agent_*` for non-adversary.\n",
    "\n",
    "Actions:\n",
    "\n",
    "- 0 is NOP\n",
    "- 1 is go left\n",
    "- 2 is go right\n",
    "- 3 is go down\n",
    "- 4 is go up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6301c6a",
   "metadata": {},
   "source": [
    "### How to train the agents?\n",
    "\n",
    "When loss is increasing for Double DQN, then increase the interval for updating target network.\n",
    "<https://stackoverflow.com/questions/56964657/cartpole-v0-loss-increasing-using-dqn>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c62b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5ad6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discount': 0.99,\n",
       " 'epsilon': 0.1,\n",
       " 'n_episodes': 20000,\n",
       " 'batch_size': 32,\n",
       " 'update_target_interval': 64,\n",
       " 'report_interval': 64,\n",
       " 'clip_grad_norm': 5.0,\n",
       " 'lr': 0.005,\n",
       " 'reward_scale': 1,\n",
       " 'device': device(type='cuda'),\n",
       " 'common': {'hidden_size': 32, 'n_rnn_layers': 1, 'n_actions': 5},\n",
       " 'adversary': {'n_agents': 1,\n",
       "  'observation_shape': (8,),\n",
       "  'hidden_size': 32,\n",
       "  'n_rnn_layers': 1,\n",
       "  'n_actions': 5},\n",
       " 'agent': {'n_agents': 1,\n",
       "  'observation_shape': (6,),\n",
       "  'hidden_size': 32,\n",
       "  'n_rnn_layers': 1,\n",
       "  'n_actions': 5}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_agent_counts():\n",
    "    all_agents = 0\n",
    "    adversaries = 0\n",
    "    for agent in env.world.agents:\n",
    "        all_agents += 1\n",
    "        adversaries += 1 if agent.adversary else 0\n",
    "    good_agents = all_agents - adversaries\n",
    "    return (adversaries, good_agents)\n",
    "\n",
    "def process_config(config):\n",
    "    for k, v in config.common.items():\n",
    "        config.adversary[k] = v\n",
    "        config.agent[k] = v\n",
    "\n",
    "n_adversaries, n_good_agents = get_agent_counts()\n",
    "config = AttrDict(\n",
    "    discount = 0.99,\n",
    "    epsilon = 0.1,\n",
    "    n_episodes=20_000,\n",
    "    batch_size=32,\n",
    "    update_target_interval=64,\n",
    "    report_interval=64,\n",
    "    clip_grad_norm=5.0,\n",
    "    lr=0.005,\n",
    "    reward_scale=1,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    common=AttrDict(\n",
    "        hidden_size=32,\n",
    "        n_rnn_layers=1,\n",
    "        n_actions=env.action_space(env.agent_selection).n,\n",
    "    ),\n",
    "    adversary=AttrDict(\n",
    "        n_agents=n_adversaries,\n",
    "        observation_shape=env.observation_space(\"adversary_0\").shape\n",
    "\n",
    "    ),\n",
    "    agent=AttrDict(\n",
    "        n_agents=n_good_agents,\n",
    "        observation_shape=env.observation_space(\"agent_0\").shape\n",
    "    )\n",
    ")\n",
    "process_config(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5224e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    def __init__(self, env):\n",
    "        self.n_landmarks = len(env.world.landmarks)\n",
    "        self.n_allagents = len(env.world.agents)\n",
    "        self.n_good = sum(map(lambda a: not a.adversary, env.world.agents))\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize_abs_pos(s):\n",
    "        \"\"\"Clip absolute position and scale to [-1, 1]\n",
    "        s is a scalar or an ndarray of one dimension.\"\"\"\n",
    "        return np.clip(s, -1.5, 1.5) / 1.5\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_rel_pos(s):\n",
    "        \"\"\"Clip relative position and scale to [-1, 1]\n",
    "        s is a scalar or an ndarray of one dimension.\"\"\"\n",
    "        return np.clip(s, -3, 3) / 3\n",
    "\n",
    "    def __call__(self, obs):\n",
    "        # normalize and clip positions\n",
    "        norm_obs = obs.copy()\n",
    "        # normalize velocity of current entity\n",
    "        norm_obs[:2] = norm_obs[:2] / 1.3\n",
    "        # clip/scale abs. position of current entity\n",
    "        norm_obs[2:4] = self.normalize_abs_pos(norm_obs[2:4])\n",
    "        # clip/scale rel. position of other entities\n",
    "        n_range = self.n_landmarks + self.n_allagents - 1\n",
    "        for i in range(n_range):\n",
    "            norm_obs[4 + (2*i):4 + (2*(i + 1))] = self.normalize_rel_pos(\n",
    "                norm_obs[4 + (2*i):4 + (2*(i + 1))]\n",
    "            )\n",
    "        # normalize velocity of other entities\n",
    "        norm_obs[4 + (2*n_range):] = norm_obs[4 + (2*n_range):] / 1.3\n",
    "        return norm_obs\n",
    "    \n",
    "class RewardsShaper(object):\n",
    "    # rdist - distance between adversary-good agent to start computing rewards.\n",
    "    rdist = 2\n",
    "    # collision_dist - distance between adversary-good agent to count collision.\n",
    "    #    Based on PettingZoo numbers. \n",
    "    collision_dist = 0.075 + 0.05\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.n_landmarks = len(env.world.landmarks)\n",
    "        # self.n_allagents = len(env.world.agents)\n",
    "        self.name_to_idx = {agent.name: i for i, agent in enumerate(env.world.agents)}\n",
    "        self.idx_to_name = {i: agent.name for i, agent in enumerate(env.world.agents)}\n",
    "        self.goodagent_indices = [\n",
    "            i for i, agent in enumerate(env.world.agents) if agent.name.startswith(\"agent\")\n",
    "        ]\n",
    "        self.adversary_indices = [\n",
    "            i for i, agent in enumerate(env.world.agents) if agent.name.startswith(\"adversary\")\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def bound(x):\n",
    "        if x < 0.9:\n",
    "            return 0\n",
    "        if x < 1.0:\n",
    "            return (x - 0.9) * 10\n",
    "        return min(np.exp(2 * x - 2), 10)\n",
    "\n",
    "    @classmethod\n",
    "    def dist_to_reward(cls, d):\n",
    "        \"\"\"Compute rewards (or penalty) that starts ~10 and decays to 0 as distance increases.\n",
    "        \"\"\"\n",
    "        # make score inverse-linear to distance\n",
    "        x = np.clip(1 - (d - cls.collision_dist)/(cls.rdist - cls.collision_dist), 0, np.inf)\n",
    "        # make score increase non-linearly\n",
    "        expscale = np.exp(3*x)/np.exp(3) - 1/np.exp(3)\n",
    "        # set max reward without collision\n",
    "        _max = 10\n",
    "        return np.clip(_max*expscale, -np.inf, _max)\n",
    "    \n",
    "    def __call__(self, agent_name, obs):\n",
    "        \"\"\"Compute reshaped rewards from observation for agent given agent name.\n",
    "        Adversary: start gaining small rewards as it nears good agents.\n",
    "        \n",
    "        Good agent: starts gaining small penality as it nears bad agents.\n",
    "        \"\"\"\n",
    "        _obs = obs[4 + (2*self.n_landmarks):]\n",
    "        agent_idx = self.name_to_idx[agent_name]\n",
    "        cum_r = 0.\n",
    "        if agent_name.startswith(\"agent\"):\n",
    "            # penalty across all adversaries\n",
    "            for adversary_idx in self.adversary_indices:\n",
    "                # penalty from distance of adversary; penalty of collision\n",
    "                other_idx = adversary_idx - 1 if agent_idx < adversary_idx else adversary_idx\n",
    "                x, y = _obs[2*other_idx:(2*other_idx) + 2]\n",
    "                d    = math.sqrt(x**2 + y**2)\n",
    "                cum_r -= max(self.dist_to_reward(d), cum_r)\n",
    "                \n",
    "            # penalty from boudary based on PettingZoo\n",
    "            pos = obs[2:4]\n",
    "            cum_r -= self.bound(abs(pos[0]))\n",
    "            cum_r -= self.bound(abs(pos[1]))\n",
    "        \n",
    "        elif agent_name.startswith(\"adversary\"):\n",
    "            # reward across all agents\n",
    "            for goodagent_idx in self.goodagent_indices:\n",
    "                # reward from distance to agent; reward of collision\n",
    "                other_idx = goodagent_idx - 1 if agent_idx < goodagent_idx else goodagent_idx\n",
    "                x, y = _obs[2*other_idx:(2*other_idx) + 2]\n",
    "                d    = math.sqrt(x**2 + y**2)\n",
    "                cum_r += max(self.dist_to_reward(d), cum_r)\n",
    "        \n",
    "        return cum_r\n",
    "\n",
    "normalize = Normalizer(env) # norm_obs = normalize(obs)\n",
    "shapereward = RewardsShaper(env) # reward = shapereward(agent_name, obs)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "criterion = torch.nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9dce3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTagNet(torch.nn.Module):\n",
    "    \"\"\"NN Model for the agents. Both good agents and adversaries use this model.\"\"\"\n",
    "        \n",
    "    def __init__(self, config, agent_type):\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.device      = config.device\n",
    "        self.observation_size = math.prod(config[agent_type].observation_shape)\n",
    "        self.n_actions   = config[agent_type].n_actions\n",
    "        self.hidden_size = config[agent_type].hidden_size\n",
    "        self.n_rnn_layers = config[agent_type].n_rnn_layers\n",
    "        inplace=True\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.observation_size, self.hidden_size),\n",
    "            torch.nn.ReLU(inplace=inplace),\n",
    "#             torch.nn.Linear(self.hidden_size, self.hidden_size),\n",
    "#             torch.nn.ReLU(inplace=inplace),\n",
    "        )\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=self.hidden_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.n_rnn_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.output_mlp = torch.nn.Linear(self.hidden_size, self.n_actions)\n",
    "    \n",
    "    def forward(self, observation, hidden=None):\n",
    "        \"\"\"Apply DQN to episode step.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        observation : ndarray\n",
    "            The observation vector obtained from the environment.\n",
    "        hidden : torch.Tensor\n",
    "            Hidden state of GRU. By default has shape (n_layers=2, N=1, H_out=128).\n",
    "        \n",
    "        Returns\n",
    "        =======\n",
    "        torch.Tensor\n",
    "            Vector of Q-value associated with each action.\n",
    "        torch.Tensor\n",
    "            The hidden state used by GRU.\n",
    "        \"\"\"\n",
    "        observation = normalize(observation)\n",
    "        observation = torch.tensor(observation, dtype=torch.float, device=self.device)\n",
    "        z = self.mlp(observation)\n",
    "        z = z.unsqueeze(0).unsqueeze(0)\n",
    "        z, hidden = self.rnn(z, hidden)\n",
    "        z = z.squeeze(0).squeeze(0)\n",
    "        Q = self.output_mlp(z)\n",
    "        return Q, hidden\n",
    "\n",
    "def choose_action(config, agent_type, Q, epsilon=0.05, is_val=False):\n",
    "    if not is_val and random.random() < epsilon:\n",
    "        return random.randrange(config[agent_type].n_actions)\n",
    "    else:\n",
    "        return torch.argmax(Q).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f86814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_episode(config, adversary_net, should_render=False, epsilon=0.05, is_val=False):\n",
    "    \"\"\"Run one episodes.\n",
    "    \n",
    "    inputs consist of observation, message (backprop), hidden (backprop) indexed by agent\n",
    "    outputs consist of action, q-value of action (backprop), reward, done indexed by (step, agent)\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    AttrDict\n",
    "        Contains episode metrics:\n",
    "        - steps : number of steps. All agents take an action at each step.\n",
    "        - reward : episodic rewards indexed by ('adversary', 'agent').\n",
    "        - step_records : list of quantities produced indiced by step, ('adversary', 'agent'), agent index.\n",
    "          Each step record has:\n",
    "            + observation\n",
    "            + Q\n",
    "            + reward\n",
    "            + done\n",
    "        - loss : contains episodic losses indexed by ('adversary', 'agent'). To be updated by train_agents()\n",
    "    \"\"\"\n",
    "    episode = AttrDict(\n",
    "        steps=0,\n",
    "        reward=AttrDict(adversary=0, agent=0),\n",
    "        step_records=[],\n",
    "        loss=AttrDict(adversary=0, agent=0)\n",
    "    )\n",
    "    n_agents = config.adversary.n_agents + config.agent.n_agents\n",
    "    step_record = None\n",
    "    hidden = None\n",
    "    env.reset()\n",
    "    for agent_step_idx, agent_name in enumerate(env.agent_iter()):\n",
    "        if agent_step_idx % n_agents == 0:\n",
    "            episode.steps += 1\n",
    "            step_record = AttrDict(adversary={}, agent={})\n",
    "            episode.step_records.append(step_record)\n",
    "            \n",
    "        obs_curr, _reward, done, _ = env.last()\n",
    "        reward = shapereward(agent_name, obs_curr)\n",
    "        if should_render:\n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "            if agent_name == \"adversary_0\":\n",
    "                # print(\"rew, shaped rew\", round(_reward, 2), round(reward, 2))\n",
    "                # print(\"obs, normed obs\", np.round(obs_curr, 2), np.round(normalize(obs_curr), 2))\n",
    "                # print(\"obs, normed obs\", np.round(obs_curr[4:6], 2), np.round(normalize(obs_curr[4:6]), 2))\n",
    "                # print(\"obs, rew\", np.round(normalize(obs_curr[4:6]), 2), reward)\n",
    "                pass\n",
    "        agent_type, agent_idx = agent_name.split(\"_\")\n",
    "        agent_idx = int(agent_idx)\n",
    "        if done:\n",
    "            step_record[agent_type][agent_idx] = AttrDict(\n",
    "                observation=obs_curr,\n",
    "                action=None,\n",
    "                Q=None,\n",
    "                reward=reward,\n",
    "                done=done,\n",
    "            )\n",
    "            env.step(None)\n",
    "            continue\n",
    "        if agent_type == \"agent\":\n",
    "            env.step(0)\n",
    "            step_record[agent_type][agent_idx] = AttrDict(\n",
    "                observation=obs_curr,\n",
    "                action=0,\n",
    "                Q=None,\n",
    "                reward=reward,\n",
    "                done=done,\n",
    "            )\n",
    "        else:\n",
    "            # agent_type == \"adversary\"\n",
    "            Q_curr, hidden = adversary_net(obs_curr, hidden)\n",
    "            action = choose_action(config, agent_type, Q_curr, epsilon, is_val=is_val)\n",
    "            env.step(action)\n",
    "            step_record[agent_type][agent_idx] = AttrDict(\n",
    "                # inputs to network\n",
    "                observation=obs_curr,\n",
    "                # outputs of network / inputs to environment\n",
    "                action=action,\n",
    "#                 Q=Q_curr,\n",
    "                Q=None,\n",
    "                # output of environment\n",
    "                reward=reward,\n",
    "                done=done,\n",
    "            )\n",
    "        episode.reward[agent_type] += reward\n",
    "    \n",
    "    if should_render:\n",
    "        env.close()\n",
    "    return episode\n",
    "\n",
    "def train_agents(config, batch, adversary_net, adversary_target_net, adversary_optimizer):\n",
    "    \"\"\"Compute loss of episode and update agent weights.\n",
    "    \"\"\"\n",
    "    adversary_optimizer.zero_grad()\n",
    "    device = config.device\n",
    "    discount = torch.tensor(config.discount, dtype=torch.float, device=device)\n",
    "    adversary_losses = []\n",
    "    for episode in batch:\n",
    "        hidden = None\n",
    "        target_hidden = None\n",
    "        for step_idx in range(episode.steps):\n",
    "            for agent_idx in episode.step_records[step_idx].adversary.keys():\n",
    "                curr_record = episode.step_records[step_idx].adversary[agent_idx]\n",
    "                if curr_record.done:\n",
    "                    # agent is done at this step\n",
    "                    continue\n",
    "                next_record = episode.step_records[step_idx + 1].adversary[agent_idx]\n",
    "                r = torch.tensor(next_record.reward, dtype=torch.float, device=device)\n",
    "                y = None\n",
    "                if next_record.done:\n",
    "                    # agent terminates at next step\n",
    "                    y = r\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        next_o = next_record.observation\n",
    "                        target_Q, target_hidden = adversary_target_net(next_o, target_hidden)\n",
    "                        max_target_Q = torch.max(target_Q)\n",
    "                        y = r + discount*max_target_Q\n",
    "                curr_o = curr_record.observation\n",
    "                u = curr_record.action\n",
    "#                 Q = curr_record.Q\n",
    "                Q, hidden = adversary_net(curr_o, hidden)\n",
    "                Q_u = Q[u]\n",
    "                # adversary_loss = torch.pow(y - Q_u, 2.)\n",
    "                adversary_losses.append(criterion(y, Q_u))\n",
    "    \n",
    "    adversary_loss = torch.mean(torch.stack(adversary_losses))\n",
    "    adversary_loss.backward()#retain_graph=True)\n",
    "    show_norms = False\n",
    "    if show_norms:\n",
    "        norms = [p.grad.detach().data.norm().item() for p in adversary_net.parameters()]\n",
    "        print(\"norm of gradiants\", *np.round(norms, 2))\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(adversary_net.parameters(), config.clip_grad_norm)\n",
    "    adversary_optimizer.step()\n",
    "    episode.loss.adversary += adversary_loss.item()\n",
    "\n",
    "def train(config):\n",
    "    \"\"\"\n",
    "    - Use parameter sharing between agents of the same class.\n",
    "    - Good agents use one RL model, adversaries use another RL model.\n",
    "      Train the agents side by side.\n",
    "    - Separate, disjoint communication channels for two classes of agents,\n",
    "      maintained by a container to store the messages.\n",
    "    \"\"\"\n",
    "    eps_start = 0.9\n",
    "    eps_end = 0.05\n",
    "    eps_decay = 0.9996\n",
    "    epsilon = eps_start\n",
    "        \n",
    "    print(\"Training the agents...\")\n",
    "    os.makedirs(\"models/batched-baseline-rnn\", exist_ok=True)\n",
    "    t0 = time.time()\n",
    "    device = config.device\n",
    "    adversary_net = SimpleTagNet(config, \"adversary\").to(device)\n",
    "    adversary_target_net = SimpleTagNet(config, \"adversary\").to(device)\n",
    "    adversary_target_net.eval()\n",
    "    print(\"Created the agent nets.\")\n",
    "    adversary_optimizer = torch.optim.SGD(adversary_net.parameters(), lr=config.lr)\n",
    "    logger = AttrDict(\n",
    "        episodic_losses=AttrDict(adversary=[], agent=[]),\n",
    "        episodic_rewards=AttrDict(adversary=[], agent=[])\n",
    "    )\n",
    "    def update_targets():\n",
    "        adversary_target_net.load_state_dict(adversary_net.state_dict())\n",
    "    print(\"Initial update of target nets\")\n",
    "    update_targets()\n",
    "    \n",
    "    batch = []\n",
    "    print(\"Beginning the episodes...\")\n",
    "    for episode_idx in range(config.n_episodes):\n",
    "        # Run an episode\n",
    "        episode = run_episode(config, adversary_net,\n",
    "                              epsilon=epsilon,\n",
    "                              should_render=episode_idx % config.report_interval == 0 and episode_idx > 0)\n",
    "        batch.append(episode)\n",
    "        epsilon = max(epsilon*eps_decay, eps_end)\n",
    "        \n",
    "        # Train on the episode\n",
    "        if episode_idx % config.batch_size == 0 and episode_idx > 0:\n",
    "            train_agents(config, batch, adversary_net,\n",
    "                         adversary_target_net,\n",
    "                         adversary_optimizer)\n",
    "            batch = []\n",
    "        \n",
    "        # Logging the reward and los\n",
    "        logger.episodic_losses.adversary.append(episode.loss.adversary)\n",
    "        logger.episodic_losses.agent.append(episode.loss.agent)\n",
    "        logger.episodic_rewards.adversary.append(episode.reward.adversary)\n",
    "        logger.episodic_rewards.agent.append(episode.reward.agent)\n",
    "\n",
    "        if episode_idx % config.update_target_interval == 0 and episode_idx > 0:\n",
    "            # Update double network\n",
    "            update_targets()\n",
    "        \n",
    "        if episode_idx % config.report_interval == 0 and episode_idx > 0:\n",
    "            # Logging\n",
    "            t1 = time.time()\n",
    "            tdelta = TimeDelta(round(t1 - t0, 0))\n",
    "            print(f\"on episode {episode_idx}, curr epsilon {epsilon:.2f} (time taken so far: {tdelta})\")\n",
    "            mean_loss_adversary = statistics.fmean(logger.episodic_losses.adversary[-config.report_interval:])\n",
    "            mean_reward_adversary = statistics.fmean(logger.episodic_rewards.adversary[-config.report_interval:])\n",
    "            mean_reward_agent = statistics.fmean(logger.episodic_rewards.agent[-config.report_interval:])\n",
    "            print(f\"     mean loss: adversary {mean_loss_adversary:.5f}\")\n",
    "            print(f\"     mean reward: adversary {mean_reward_adversary:.2f}, agent {mean_reward_agent:.2f}\")\n",
    "            torch.save(\n",
    "                adversary_net.state_dict(),\n",
    "                f\"models/batched-baseline-rnn/adversary-net-{episode_idx}.pth\"\n",
    "            )\n",
    "    \n",
    "    return adversary_net, logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d67b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0210fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the agents...\n",
      "Created the agent nets.\n",
      "Initial update of target nets\n",
      "Beginning the episodes...\n",
      "on episode 64, curr epsilon 0.88 (time taken so far: 0-00:00:10.0)\n",
      "     mean loss: adversary 0.07049\n",
      "     mean reward: adversary 80.07, agent -84.44\n",
      "on episode 128, curr epsilon 0.85 (time taken so far: 0-00:00:16.0)\n",
      "     mean loss: adversary 0.07323\n",
      "     mean reward: adversary 81.08, agent -82.41\n",
      "on episode 192, curr epsilon 0.83 (time taken so far: 0-00:00:22.0)\n",
      "     mean loss: adversary 0.06592\n",
      "     mean reward: adversary 74.78, agent -77.81\n",
      "on episode 256, curr epsilon 0.81 (time taken so far: 0-00:00:29.0)\n",
      "     mean loss: adversary 0.07565\n",
      "     mean reward: adversary 83.40, agent -87.33\n",
      "on episode 320, curr epsilon 0.79 (time taken so far: 0-00:00:35.0)\n",
      "     mean loss: adversary 0.06801\n",
      "     mean reward: adversary 76.24, agent -79.52\n",
      "on episode 384, curr epsilon 0.77 (time taken so far: 0-00:00:41.0)\n",
      "     mean loss: adversary 0.06485\n",
      "     mean reward: adversary 73.10, agent -75.67\n",
      "on episode 448, curr epsilon 0.75 (time taken so far: 0-00:00:47.0)\n",
      "     mean loss: adversary 0.06511\n",
      "     mean reward: adversary 74.18, agent -77.50\n",
      "on episode 512, curr epsilon 0.73 (time taken so far: 0-00:00:53.0)\n",
      "     mean loss: adversary 0.06169\n",
      "     mean reward: adversary 70.05, agent -72.17\n",
      "on episode 576, curr epsilon 0.71 (time taken so far: 0-00:00:59.0)\n",
      "     mean loss: adversary 0.05613\n",
      "     mean reward: adversary 64.10, agent -66.49\n",
      "on episode 640, curr epsilon 0.70 (time taken so far: 0-00:01:5.0)\n",
      "     mean loss: adversary 0.06662\n",
      "     mean reward: adversary 74.44, agent -77.76\n",
      "on episode 704, curr epsilon 0.68 (time taken so far: 0-00:01:12.0)\n",
      "     mean loss: adversary 0.06845\n",
      "     mean reward: adversary 77.57, agent -78.78\n",
      "on episode 768, curr epsilon 0.66 (time taken so far: 0-00:01:18.0)\n",
      "     mean loss: adversary 0.05959\n",
      "     mean reward: adversary 69.82, agent -71.55\n",
      "on episode 832, curr epsilon 0.64 (time taken so far: 0-00:01:24.0)\n",
      "     mean loss: adversary 0.05038\n",
      "     mean reward: adversary 59.75, agent -63.47\n",
      "on episode 896, curr epsilon 0.63 (time taken so far: 0-00:01:30.0)\n",
      "     mean loss: adversary 0.05988\n",
      "     mean reward: adversary 69.14, agent -73.44\n",
      "on episode 960, curr epsilon 0.61 (time taken so far: 0-00:01:36.0)\n",
      "     mean loss: adversary 0.05343\n",
      "     mean reward: adversary 62.47, agent -65.32\n",
      "on episode 1024, curr epsilon 0.60 (time taken so far: 0-00:01:42.0)\n",
      "     mean loss: adversary 0.05357\n",
      "     mean reward: adversary 62.38, agent -65.76\n",
      "on episode 1088, curr epsilon 0.58 (time taken so far: 0-00:01:49.0)\n",
      "     mean loss: adversary 0.07909\n",
      "     mean reward: adversary 88.11, agent -92.41\n",
      "on episode 1152, curr epsilon 0.57 (time taken so far: 0-00:01:55.0)\n",
      "     mean loss: adversary 0.05252\n",
      "     mean reward: adversary 61.08, agent -64.15\n",
      "on episode 1216, curr epsilon 0.55 (time taken so far: 0-00:02:1.0)\n",
      "     mean loss: adversary 0.06616\n",
      "     mean reward: adversary 75.31, agent -76.75\n",
      "on episode 1280, curr epsilon 0.54 (time taken so far: 0-00:02:7.0)\n",
      "     mean loss: adversary 0.05487\n",
      "     mean reward: adversary 63.04, agent -66.73\n",
      "on episode 1344, curr epsilon 0.53 (time taken so far: 0-00:02:13.0)\n",
      "     mean loss: adversary 0.05821\n",
      "     mean reward: adversary 67.95, agent -69.42\n",
      "on episode 1408, curr epsilon 0.51 (time taken so far: 0-00:02:19.0)\n",
      "     mean loss: adversary 0.06579\n",
      "     mean reward: adversary 75.11, agent -79.11\n",
      "on episode 1472, curr epsilon 0.50 (time taken so far: 0-00:02:26.0)\n",
      "     mean loss: adversary 0.06019\n",
      "     mean reward: adversary 68.76, agent -70.15\n",
      "on episode 1536, curr epsilon 0.49 (time taken so far: 0-00:02:32.0)\n",
      "     mean loss: adversary 0.04761\n",
      "     mean reward: adversary 56.45, agent -60.87\n",
      "on episode 1600, curr epsilon 0.47 (time taken so far: 0-00:02:38.0)\n",
      "     mean loss: adversary 0.05543\n",
      "     mean reward: adversary 64.39, agent -67.70\n",
      "on episode 1664, curr epsilon 0.46 (time taken so far: 0-00:02:44.0)\n",
      "     mean loss: adversary 0.04728\n",
      "     mean reward: adversary 56.88, agent -60.52\n",
      "on episode 1728, curr epsilon 0.45 (time taken so far: 0-00:02:50.0)\n",
      "     mean loss: adversary 0.04710\n",
      "     mean reward: adversary 56.24, agent -58.81\n",
      "on episode 1792, curr epsilon 0.44 (time taken so far: 0-00:02:57.0)\n",
      "     mean loss: adversary 0.05208\n",
      "     mean reward: adversary 61.02, agent -63.25\n",
      "on episode 1856, curr epsilon 0.43 (time taken so far: 0-00:03:3.0)\n",
      "     mean loss: adversary 0.04198\n",
      "     mean reward: adversary 51.96, agent -53.90\n",
      "on episode 1920, curr epsilon 0.42 (time taken so far: 0-00:03:9.0)\n",
      "     mean loss: adversary 0.05939\n",
      "     mean reward: adversary 68.92, agent -72.06\n",
      "on episode 1984, curr epsilon 0.41 (time taken so far: 0-00:03:15.0)\n",
      "     mean loss: adversary 0.06163\n",
      "     mean reward: adversary 71.16, agent -73.66\n",
      "on episode 2048, curr epsilon 0.40 (time taken so far: 0-00:03:21.0)\n",
      "     mean loss: adversary 0.04370\n",
      "     mean reward: adversary 52.69, agent -55.40\n",
      "on episode 2112, curr epsilon 0.39 (time taken so far: 0-00:03:28.0)\n",
      "     mean loss: adversary 0.05262\n",
      "     mean reward: adversary 61.93, agent -64.16\n",
      "on episode 2176, curr epsilon 0.38 (time taken so far: 0-00:03:34.0)\n",
      "     mean loss: adversary 0.04703\n",
      "     mean reward: adversary 55.85, agent -58.90\n",
      "on episode 2240, curr epsilon 0.37 (time taken so far: 0-00:03:40.0)\n",
      "     mean loss: adversary 0.04885\n",
      "     mean reward: adversary 58.43, agent -61.17\n",
      "on episode 2304, curr epsilon 0.36 (time taken so far: 0-00:03:46.0)\n",
      "     mean loss: adversary 0.03629\n",
      "     mean reward: adversary 44.33, agent -45.67\n",
      "on episode 2368, curr epsilon 0.35 (time taken so far: 0-00:03:52.0)\n",
      "     mean loss: adversary 0.05040\n",
      "     mean reward: adversary 58.63, agent -63.35\n",
      "on episode 2432, curr epsilon 0.34 (time taken so far: 0-00:03:59.0)\n",
      "     mean loss: adversary 0.04429\n",
      "     mean reward: adversary 53.80, agent -57.17\n",
      "on episode 2496, curr epsilon 0.33 (time taken so far: 0-00:04:5.0)\n",
      "     mean loss: adversary 0.03769\n",
      "     mean reward: adversary 45.74, agent -48.08\n",
      "on episode 2560, curr epsilon 0.32 (time taken so far: 0-00:04:11.0)\n",
      "     mean loss: adversary 0.04086\n",
      "     mean reward: adversary 49.64, agent -52.42\n",
      "on episode 2624, curr epsilon 0.31 (time taken so far: 0-00:04:17.0)\n",
      "     mean loss: adversary 0.04346\n",
      "     mean reward: adversary 51.99, agent -54.02\n",
      "on episode 2688, curr epsilon 0.31 (time taken so far: 0-00:04:23.0)\n",
      "     mean loss: adversary 0.04374\n",
      "     mean reward: adversary 51.69, agent -55.66\n",
      "on episode 2752, curr epsilon 0.30 (time taken so far: 0-00:04:29.0)\n",
      "     mean loss: adversary 0.04394\n",
      "     mean reward: adversary 52.50, agent -56.81\n",
      "on episode 2816, curr epsilon 0.29 (time taken so far: 0-00:04:36.0)\n",
      "     mean loss: adversary 0.03663\n",
      "     mean reward: adversary 45.50, agent -48.47\n",
      "on episode 2880, curr epsilon 0.28 (time taken so far: 0-00:04:42.0)\n",
      "     mean loss: adversary 0.05195\n",
      "     mean reward: adversary 61.42, agent -63.99\n",
      "on episode 2944, curr epsilon 0.28 (time taken so far: 0-00:04:48.0)\n",
      "     mean loss: adversary 0.04414\n",
      "     mean reward: adversary 53.62, agent -57.41\n",
      "on episode 3008, curr epsilon 0.27 (time taken so far: 0-00:04:54.0)\n",
      "     mean loss: adversary 0.03873\n",
      "     mean reward: adversary 47.07, agent -50.44\n",
      "on episode 3072, curr epsilon 0.26 (time taken so far: 0-00:05:1.0)\n",
      "     mean loss: adversary 0.03747\n",
      "     mean reward: adversary 45.54, agent -50.08\n",
      "on episode 3136, curr epsilon 0.26 (time taken so far: 0-00:05:7.0)\n",
      "     mean loss: adversary 0.04332\n",
      "     mean reward: adversary 51.58, agent -53.78\n",
      "on episode 3200, curr epsilon 0.25 (time taken so far: 0-00:05:13.0)\n",
      "     mean loss: adversary 0.03953\n",
      "     mean reward: adversary 48.15, agent -52.13\n",
      "on episode 3264, curr epsilon 0.24 (time taken so far: 0-00:05:19.0)\n",
      "     mean loss: adversary 0.04560\n",
      "     mean reward: adversary 53.85, agent -56.54\n",
      "on episode 3328, curr epsilon 0.24 (time taken so far: 0-00:05:25.0)\n",
      "     mean loss: adversary 0.03977\n",
      "     mean reward: adversary 48.79, agent -52.63\n",
      "on episode 3392, curr epsilon 0.23 (time taken so far: 0-00:05:32.0)\n",
      "     mean loss: adversary 0.03887\n",
      "     mean reward: adversary 48.03, agent -51.58\n",
      "on episode 3456, curr epsilon 0.23 (time taken so far: 0-00:05:38.0)\n",
      "     mean loss: adversary 0.03424\n",
      "     mean reward: adversary 42.92, agent -45.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on episode 3520, curr epsilon 0.22 (time taken so far: 0-00:05:44.0)\n",
      "     mean loss: adversary 0.04139\n",
      "     mean reward: adversary 49.13, agent -53.85\n",
      "on episode 3584, curr epsilon 0.21 (time taken so far: 0-00:05:50.0)\n",
      "     mean loss: adversary 0.03782\n",
      "     mean reward: adversary 45.64, agent -48.92\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3824/3639264787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madversary_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3824/3079184496.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Train on the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepisode_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepisode_idx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             train_agents(config, batch, adversary_net,\n\u001b[0m\u001b[1;32m    182\u001b[0m                          \u001b[0madversary_target_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                          adversary_optimizer)\n",
      "\u001b[0;32m/tmp/ipykernel_3824/3079184496.py\u001b[0m in \u001b[0;36mtrain_agents\u001b[0;34m(config, batch, adversary_net, adversary_target_net, adversary_optimizer)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#                 Q = curr_record.Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversary_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mQ_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;31m# adversary_loss = torch.pow(y - Q_u, 2.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3824/3114587224.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation, hidden)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    838\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "adversary_net, logger = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91f38a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efbd3510a30>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps_start = 0.9\n",
    "eps_end = 0.05\n",
    "eps_decay = 0.9996\n",
    "epsilon = eps_start\n",
    "\n",
    "eps = [epsilon]\n",
    "for i in range(10_000):\n",
    "    epsilon = max((epsilon*eps_decay), eps_end)\n",
    "    eps.append(epsilon)\n",
    "\n",
    "plt.plot(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92f014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load adversary net\n",
    "adversary_net = SimpleTagNet(config, \"adversary\").to(config.device)\n",
    "adversary_net.load_state_dict(torch.load('./models/batched-baseline-rnn/adversary-net-19968.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af941f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save logs\n",
    "with open(\"models/batched-baseline-rnn/log.json\", \"w\") as f:\n",
    "    json.dump(logger, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654746eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc8b95dac40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].plot(logger.episodic_losses.adversary[50:], label=\"adversary\")\n",
    "axes[0].plot(logger.episodic_losses.agent[50:], label=\"good agent\")\n",
    "axes[0].set_title(\"loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(logger.episodic_rewards.adversary[50:], label=\"adversary\")\n",
    "axes[1].plot(logger.episodic_rewards.agent[50:], label=\"good agent\")\n",
    "axes[1].set_title(\"reward\")\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"models/batched-baseline-rnn/vis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7543b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load logs\n",
    "with open(\"models/batched-baseline-rnn/log.json\", \"r\") as f:\n",
    "    logger = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def f(a, n):\n",
    "    \"\"\"Zero out beginning of last axis\"\"\"\n",
    "    pad_width = [(0, 0) for _ in range(a.ndim - 1)] + [(n, 0)]\n",
    "    return np.pad(a, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].plot(logger[\"episodic_losses\"][\"adversary\"][50:], label=\"adversary\")\n",
    "axes[0].plot(logger[\"episodic_losses\"][\"agent\"][50:], label=\"good agent\")\n",
    "axes[0].set_title(\"loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "adversary_episodic_rewards = np.array(logger[\"episodic_rewards\"][\"adversary\"])*10\n",
    "mean_adversary_episodic_rewards = f(moving_average(adversary_episodic_rewards, n=512), 0)\n",
    "# axes[1].plot(adversary_episodic_rewards, label=\"adversary\")\n",
    "axes[1].plot(mean_adversary_episodic_rewards, label=\"adversary mean\")\n",
    "# axes[1].plot(logger[\"episodic_rewards\"][\"agent\"][50:], label=\"good agent\")\n",
    "axes[1].set_title(\"reward\")\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7f65c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode steps 31\n",
      "episode rewards ('adversary', 34.37761549440293) ('agent', -34.37761549440293)\n"
     ]
    }
   ],
   "source": [
    "def visualize(config, adversary_net):\n",
    "    adversary_net.eval()\n",
    "    with torch.no_grad():\n",
    "        return run_episode(config, adversary_net, should_render=True, is_val=True)\n",
    "\n",
    "episode = visualize(config, adversary_net)\n",
    "print(\"episode steps\", episode.steps)\n",
    "print(\"episode rewards\", *episode.reward.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53717a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
