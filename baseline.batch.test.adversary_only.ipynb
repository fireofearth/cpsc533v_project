{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a622b81",
   "metadata": {},
   "source": [
    "Simple Tag\n",
    "https://www.pettingzoo.ml/mpe/simple_tag\n",
    "\n",
    "> This is a predator-prey environment. Good agents (green) are faster and receive a negative reward for being hit by adversaries (red) (-10 for each collision). Adversaries are slower and are rewarded for hitting good agents (+10 for each collision). Obstacles (large black circles) block the way. By default, there is 1 good agent, 3 adversaries and 2 obstacles.\n",
    "\n",
    "Baseline agent algorithm with experience replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f7b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import enum\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "class TimeDelta(object):\n",
    "    def __init__(self, delta_time):\n",
    "        \"\"\"Convert time difference in seconds to days, hours, minutes, seconds.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        delta_time : float\n",
    "            Time difference in seconds.\n",
    "        \"\"\"\n",
    "        self.fractional, seconds = math.modf(delta_time)\n",
    "        seconds = int(seconds)\n",
    "        minutes, self.seconds = divmod(seconds, 60)\n",
    "        hours, self.minutes = divmod(minutes, 60)\n",
    "        self.days, self.hours = divmod(hours, 24)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.days}-{self.hours:02}:{self.minutes:02}:{self.seconds + self.fractional:02}\"\n",
    "        \n",
    "from pettingzoo.mpe import simple_tag_v2\n",
    "from pettingzoo.utils import random_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7724bfe",
   "metadata": {},
   "source": [
    "Arguments in instantiate environment.\n",
    "\n",
    "- num_good: number of good agents\n",
    "- num_adversaries: number of adversaries\n",
    "- num_obstacles: number of obstacles\n",
    "- max_cycles: number of frames (a step for each agent) until game terminates\n",
    "- continuous_actions: Whether agent action spaces are discrete(default) or continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9858b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simple_tag_v2.env(\n",
    "    num_good=1,\n",
    "    num_adversaries=1,\n",
    "    num_obstacles=0,\n",
    "    max_cycles=300,\n",
    "    continuous_actions=False\n",
    ").unwrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cabc86",
   "metadata": {},
   "source": [
    "### What are the environment parameters?\n",
    "\n",
    "Adversaries (red) capture non-adversary (green). The map is a 2D grid and everything is initialized in the region [-1, +1]. There doesn't seem to be position clipping for out of bounds, but non-adversary agent are penalized for out of bounds.\n",
    "Agent's observation is a ndarray vector of concatenated data in the following order:\n",
    "\n",
    "1. current velocity (2,)\n",
    "2. current position (2,)\n",
    "3. relative position (2,) of each landmark\n",
    "4. relative position (2,) of each other agent\n",
    "5. velocity (2,) of each other non-adversary agent\n",
    "\n",
    "When there are 3 adverseries and 3 non-adversaries, then advarsary observation space is 24 dimensional and non-advarsary observation space is 22 dimensional.\n",
    "\n",
    "The environment is sequential. Agents move one at a time. Agents are either `adversary_*` for adversary or `agent_*` for non-adversary.\n",
    "\n",
    "Actions:\n",
    "\n",
    "- 0 is NOP\n",
    "- 1 is go left\n",
    "- 2 is go right\n",
    "- 3 is go down\n",
    "- 4 is go up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6301c6a",
   "metadata": {},
   "source": [
    "### How to train the agents?\n",
    "\n",
    "- Use the differental inter-agent learning (DIAL) algorithm.\n",
    "- Use parameter sharing for DAIL agents. Separate parameter sets for adversary agents and good agents.\n",
    "- It's not entirely clear the authors accumulate gradients for differentiable communication, but it \n",
    "\n",
    "Messages are vectors. Length 4, 5 should work.\n",
    "\n",
    "Concatenate the messages from all the actors and add them to the message input for the current agent.\n",
    "\n",
    "The names of agents are: \n",
    "adversary_0 adversary_1 adversary_2 agent_0 agent_1 agent_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c62b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5ad6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discount': 0.99,\n",
       " 'epsilon': 0.05,\n",
       " 'n_episodes': 600,\n",
       " 'batch_size': 16,\n",
       " 'update_target_interval': 32,\n",
       " 'report_interval': 64,\n",
       " 'clip_grad_norm': 2.0,\n",
       " 'lr': 0.005,\n",
       " 'device': device(type='cuda'),\n",
       " 'common': {'message_size': 4,\n",
       "  'hidden_size': 128,\n",
       "  'n_actions': 5,\n",
       "  'n_rnn_layers': 2,\n",
       "  'apply_bn': False},\n",
       " 'adversary': {'n_agents': 1,\n",
       "  'observation_shape': (8,),\n",
       "  'message_size': 4,\n",
       "  'hidden_size': 128,\n",
       "  'n_actions': 5,\n",
       "  'n_rnn_layers': 2,\n",
       "  'apply_bn': False},\n",
       " 'agent': {'n_agents': 1,\n",
       "  'observation_shape': (6,),\n",
       "  'message_size': 4,\n",
       "  'hidden_size': 128,\n",
       "  'n_actions': 5,\n",
       "  'n_rnn_layers': 2,\n",
       "  'apply_bn': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_agent_counts():\n",
    "    all_agents = 0\n",
    "    adversaries = 0\n",
    "    for agent in env.world.agents:\n",
    "        all_agents += 1\n",
    "        adversaries += 1 if agent.adversary else 0\n",
    "    good_agents = all_agents - adversaries\n",
    "    return (adversaries, good_agents)\n",
    "\n",
    "def process_config(config):\n",
    "    for k, v in config.common.items():\n",
    "        config.adversary[k] = v\n",
    "        config.agent[k] = v\n",
    "\n",
    "n_adversaries, n_good_agents = get_agent_counts()\n",
    "config = AttrDict(\n",
    "    discount = 0.99,\n",
    "    epsilon = 0.05,\n",
    "    n_episodes=600,\n",
    "    batch_size=16,\n",
    "    update_target_interval=32,\n",
    "    report_interval=64,\n",
    "    clip_grad_norm=2.,\n",
    "    lr=0.005,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    common=AttrDict(\n",
    "        message_size=4,\n",
    "        hidden_size=128,\n",
    "        n_actions=env.action_space(env.agent_selection).n,\n",
    "        n_rnn_layers=2,\n",
    "        apply_bn=False,\n",
    "    ),\n",
    "    adversary=AttrDict(\n",
    "        n_agents=n_adversaries,\n",
    "        observation_shape=env.observation_space(\"adversary_0\").shape\n",
    "\n",
    "    ),\n",
    "    agent=AttrDict(\n",
    "        n_agents=n_good_agents,\n",
    "        observation_shape=env.observation_space(\"agent_0\").shape\n",
    "    )\n",
    ")\n",
    "process_config(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9dce3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTagNet(torch.nn.Module):\n",
    "    \"\"\"NN Model for the agents. Both good agents and adversaries use this model.\"\"\"\n",
    "        \n",
    "    def __init__(self, config, agent_type):\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.device      = config.device\n",
    "        self.observation_size = math.prod(config[agent_type].observation_shape)\n",
    "        self.n_actions   = config[agent_type].n_actions\n",
    "        self.hidden_size = config[agent_type].hidden_size\n",
    "        self.output_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.observation_size, self.hidden_size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(self.hidden_size, self.n_actions)\n",
    "        )\n",
    "    \n",
    "    def forward(self, observation):\n",
    "        \"\"\"Apply DQN to episode step.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        observation : ndarray\n",
    "            The observation vector obtained from the environment.\n",
    "        \n",
    "        Returns\n",
    "        =======\n",
    "        torch.Tensor\n",
    "            Vector of Q-value associated with each action.\n",
    "        \"\"\"\n",
    "        observation = torch.tensor(observation, dtype=torch.float, device=self.device)\n",
    "        Q = self.output_mlp(observation)\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f86814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def choose_action(config, agent_type, Q, is_val=False):\n",
    "    if not is_val and random.random() < config.epsilon:\n",
    "        return random.randrange(config[agent_type].n_actions)\n",
    "    else:\n",
    "        return torch.argmax(Q).item()\n",
    "\n",
    "def run_episode(config, adversary_net, should_render=False, is_val=False):\n",
    "    \"\"\"Run one episodes.\n",
    "    \n",
    "    inputs consist of observation, message (backprop), hidden (backprop) indexed by agent\n",
    "    outputs consist of action, q-value of action (backprop), reward, done indexed by (step, agent)\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    AttrDict\n",
    "        Contains episode metrics:\n",
    "        - steps : number of steps. All agents take an action at each step.\n",
    "        - reward : episodic rewards indexed by ('adversary', 'agent').\n",
    "        - step_records : list of quantities produced indiced by step, ('adversary', 'agent'), agent index.\n",
    "          Each step record has:\n",
    "            + observation\n",
    "            + Q\n",
    "            + reward\n",
    "            + done\n",
    "        - loss : contains episodic losses indexed by ('adversary', 'agent'). To be updated by train_agents()\n",
    "    \"\"\"\n",
    "    episode = AttrDict(\n",
    "        steps=0,\n",
    "        reward=AttrDict(adversary=0, agent=0),\n",
    "        step_records=[],\n",
    "        loss=AttrDict(adversary=0, agent=0)\n",
    "    )\n",
    "    n_agents = config.adversary.n_agents + config.agent.n_agents\n",
    "    step_record = None\n",
    "    \n",
    "    env.reset()\n",
    "    for agent_step_idx, agent_name in enumerate(env.agent_iter()):\n",
    "        if should_render:\n",
    "            env.render()\n",
    "        if agent_step_idx % n_agents == 0:\n",
    "            episode.steps += 1\n",
    "            step_record = AttrDict(adversary={}, agent={})\n",
    "            episode.step_records.append(step_record)\n",
    "            \n",
    "        obs_curr, reward, done, _ = env.last()\n",
    "        agent_type, agent_idx = agent_name.split(\"_\")\n",
    "        agent_idx = int(agent_idx)\n",
    "        if done:\n",
    "            step_record[agent_type][agent_idx] = AttrDict(\n",
    "                observation=obs_curr,\n",
    "                action=None,\n",
    "                Q=None,\n",
    "                reward=reward,\n",
    "                done=done,\n",
    "            )\n",
    "            env.step(None)\n",
    "            continue\n",
    "        if agent_type == \"agent\":\n",
    "            env.step(0)\n",
    "            step_record[agent_type][agent_idx] = AttrDict(\n",
    "                observation=obs_curr,\n",
    "                action=0,\n",
    "                Q=None,\n",
    "                reward=reward,\n",
    "                done=done,\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        Q_curr = adversary_net(obs_curr)\n",
    "        action = choose_action(config, agent_type, Q_curr, is_val=is_val)\n",
    "        env.step(action)\n",
    "        step_record[agent_type][agent_idx] = AttrDict(\n",
    "            # inputs to network\n",
    "            observation=obs_curr,\n",
    "            # outputs of network / inputs to environment\n",
    "            action=action,\n",
    "            Q=Q_curr,\n",
    "            # output of environment\n",
    "            reward=reward,\n",
    "            done=done,\n",
    "        )\n",
    "        episode.reward[agent_type] += reward\n",
    "    \n",
    "    return episode\n",
    "\n",
    "def train_agents(config, batch, adversary_net,\n",
    "                 adversary_target_net,\n",
    "                 adversary_optimizer):\n",
    "    \"\"\"Compute loss of episode and update agent weights.\n",
    "    \"\"\"\n",
    "    device = config.device\n",
    "    discount = torch.tensor(config.discount, dtype=torch.float, device=device)\n",
    "    adversary_loss = torch.tensor(0., device=device)\n",
    "    for episode in batch:\n",
    "        for step_idx in range(episode.steps):\n",
    "            for agent_idx in episode.step_records[step_idx].adversary.keys():\n",
    "                curr_record = episode.step_records[step_idx].adversary[agent_idx]\n",
    "                if curr_record.done:\n",
    "                    # agent is done at this step\n",
    "                    continue\n",
    "                next_record = episode.step_records[step_idx + 1].adversary[agent_idx]\n",
    "                r = torch.tensor(next_record.reward, dtype=torch.float, device=device)\n",
    "                y = None\n",
    "                if next_record.done:\n",
    "                    # agent terminates at next step\n",
    "                    y = r\n",
    "                else:\n",
    "                    next_o = next_record.observation\n",
    "                    with torch.no_grad():\n",
    "                        target_Q = adversary_target_net(next_o)\n",
    "                        max_target_Q = torch.max(target_Q)\n",
    "                        y = r + discount*max_target_Q\n",
    "                u = curr_record.action\n",
    "                Q_u = curr_record.Q[u]\n",
    "                adversary_loss = adversary_loss + torch.pow(y - Q_u, 2.)\n",
    "    \n",
    "    n_adversary = torch.tensor(config.adversary.n_agents, dtype=torch.float, device=device)\n",
    "    n_agent = torch.tensor(config.agent.n_agents, dtype=torch.float, device=device)\n",
    "    bs = torch.tensor(config.batch_size, dtype=torch.float, device=device)\n",
    "    adversary_loss = adversary_loss / (bs * n_adversary)\n",
    "    adversary_optimizer.zero_grad()\n",
    "#     torch.nn.utils.clip_grad_norm_(adversary_net.parameters(), config.clip_grad_norm)\n",
    "#     torch.nn.utils.clip_grad_norm_(agent_net.parameters(), config.clip_grad_norm)\n",
    "    adversary_loss.backward()\n",
    "    adversary_optimizer.step()\n",
    "    episode.loss = AttrDict(adversary=adversary_loss.item(), agent=0.)\n",
    "    \n",
    "\n",
    "def train(config):\n",
    "    \"\"\"\n",
    "    - Use parameter sharing between agents of the same class.\n",
    "    - Good agents use one RL model, adversaries use another RL model.\n",
    "      Train the agents side by side.\n",
    "    - Separate, disjoint communication channels for two classes of agents,\n",
    "      maintained by a container to store the messages.\n",
    "    \"\"\"\n",
    "    print(\"Training the agents...\")\n",
    "    os.makedirs(\"models/batched-baseline-test\", exist_ok=True)\n",
    "    t0 = time.time()\n",
    "    device = config.device\n",
    "    adversary_net = SimpleTagNet(config, \"adversary\").to(device)\n",
    "    adversary_target_net = SimpleTagNet(config, \"adversary\").to(device)\n",
    "    adversary_target_net.eval()\n",
    "    print(\"Created the agent nets.\")\n",
    "    adversary_optimizer = torch.optim.SGD(adversary_net.parameters(), lr=config.lr)\n",
    "    logger = AttrDict(\n",
    "        episodic_losses=AttrDict(adversary=[], agent=[]),\n",
    "        episodic_rewards=AttrDict(adversary=[], agent=[])\n",
    "    )\n",
    "    def update_targets():\n",
    "        adversary_target_net.load_state_dict(adversary_net.state_dict())\n",
    "    print(\"Initial update of target nets\")\n",
    "    update_targets()\n",
    "    \n",
    "    batch = []\n",
    "    print(\"Beginning the episodes...\")\n",
    "    for episode_idx in range(config.n_episodes):\n",
    "        # Run an episode\n",
    "        episode = run_episode(config, adversary_net,\n",
    "                              should_render=episode_idx % config.report_interval == 0 and episode_idx > 0)\n",
    "        batch.append(episode)\n",
    "        \n",
    "        # Train on the episode\n",
    "        if episode_idx % config.batch_size == 0 and episode_idx > 0:\n",
    "            train_agents(config, batch, adversary_net,\n",
    "                         adversary_target_net,\n",
    "                         adversary_optimizer)\n",
    "            batch = []\n",
    "        \n",
    "        # Logging the reward and los\n",
    "        logger.episodic_losses.adversary.append(episode.loss.adversary)\n",
    "        logger.episodic_losses.agent.append(episode.loss.agent)\n",
    "        logger.episodic_rewards.adversary.append(episode.reward.adversary)\n",
    "        logger.episodic_rewards.agent.append(episode.reward.agent)\n",
    "\n",
    "        if episode_idx % config.update_target_interval == 0 and episode_idx > 0:\n",
    "            # Update double network\n",
    "            update_targets()\n",
    "        \n",
    "        if episode_idx % config.report_interval == 0 and episode_idx > 0:\n",
    "            # Logging\n",
    "            t1 = time.time()\n",
    "            tdelta = TimeDelta(round(t1 - t0, 0))\n",
    "            print(f\"on episode {episode_idx} (time taken so far: {tdelta})\")\n",
    "            mean_loss_adversary = statistics.fmean(logger.episodic_losses.adversary[-config.report_interval:])\n",
    "            mean_reward_adversary = statistics.fmean(logger.episodic_rewards.adversary[-config.report_interval:])\n",
    "            mean_reward_agent = statistics.fmean(logger.episodic_rewards.agent[-config.report_interval:])\n",
    "            print(f\"     mean loss: adversary {mean_loss_adversary}\")\n",
    "            print(f\"     mean reward: adversary {mean_reward_adversary}, agent {mean_reward_agent}\")\n",
    "            torch.save(\n",
    "                adversary_net.state_dict(),\n",
    "                f\"models/batched-baseline-test/adversary-net-{episode_idx}.pth\"\n",
    "            )\n",
    "    \n",
    "    return adversary_net, logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0210fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the agents...\n",
      "Created the agent nets.\n",
      "Initial update of target nets\n",
      "Beginning the episodes...\n",
      "on episode 64 (time taken so far: 0-00:00:13.0)\n",
      "     mean loss: adversary 229249.30341261625\n",
      "     mean reward: adversary 2.03125, agent 0.0\n",
      "on episode 128 (time taken so far: 0-00:00:25.0)\n",
      "     mean loss: adversary nan\n",
      "     mean reward: adversary 0.9375, agent 0.0\n",
      "on episode 192 (time taken so far: 0-00:00:37.0)\n",
      "     mean loss: adversary nan\n",
      "     mean reward: adversary 1.71875, agent 0.0\n",
      "on episode 256 (time taken so far: 0-00:00:49.0)\n",
      "     mean loss: adversary nan\n",
      "     mean reward: adversary 0.625, agent 0.0\n",
      "on episode 320 (time taken so far: 0-00:01:2.0)\n",
      "     mean loss: adversary nan\n",
      "     mean reward: adversary 1.40625, agent 0.0\n",
      "on episode 384 (time taken so far: 0-00:01:15.0)\n",
      "     mean loss: adversary nan\n",
      "     mean reward: adversary 0.78125, agent 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8964/3639264787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madversary_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8964/9572226.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Run an episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         episode = run_episode(config, adversary_net,\n\u001b[0m\u001b[1;32m    160\u001b[0m                               should_render=episode_idx % config.report_interval == 0 and episode_idx > 0)\n\u001b[1;32m    161\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8964/9572226.py\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(config, adversary_net, should_render, is_val)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mQ_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversary_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8964/751958442.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[1;32m     30\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/miniconda3/envs/ml8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "adversary_net, logger = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92f014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversary_net = SimpleTagNet(config, \"adversary\").to(config.device)\n",
    "agent_net = SimpleTagNet(config, \"agent\").to(config.device)\n",
    "adversary_net.load_state_dict(torch.load('./models/batched-baseline/adversary-net-448.pth'))\n",
    "agent_net.load_state_dict(torch.load('./models/batched-baseline/agent-net-448.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654746eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].plot(logger.episodic_losses.adversary[50:], label=\"adversary\")\n",
    "axes[0].plot(logger.episodic_losses.agent[50:], label=\"good agent\")\n",
    "axes[0].set_title(\"loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(logger.episodic_rewards.adversary[50:], label=\"adversary\")\n",
    "axes[1].plot(logger.episodic_rewards.agent[50:], label=\"good agent\")\n",
    "axes[1].set_title(\"reward\")\n",
    "axes[1].legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f65c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode steps 301\n",
      "episode rewards ('adversary', 0.0) ('agent', 0)\n"
     ]
    }
   ],
   "source": [
    "def visualize(config, adversary_net):\n",
    "    adversary_net.eval()\n",
    "    with torch.no_grad():\n",
    "        return run_episode(config, adversary_net, should_render=True, is_val=True)\n",
    "\n",
    "episode = visualize(config, adversary_net)\n",
    "print(\"episode steps\", episode.steps)\n",
    "print(\"episode rewards\", *episode.reward.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53717a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
